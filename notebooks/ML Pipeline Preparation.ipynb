{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\peter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\peter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\peter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\peter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\peter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Import necessary libraries for the pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# using word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.data.clear_cache()\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Initialize stop words and lemmatizer\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine(\"sqlite:///DesastrousDatabase.db\")\n",
    "# number of sample for generating model\n",
    "n = 0\n",
    "if n != 0:\n",
    "    df = pd.read_sql_table(\"categorized_massages\", engine).sample(n)\n",
    "else:\n",
    "    df = pd.read_sql_table(\"categorized_massages\", engine)\n",
    "X = df[\"message\"]\n",
    "Y = df.drop(columns=[\"id\", \"message\", \"original\", \"genre\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "def tokenize(text):\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(tokenizer=tokenize)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", MultiOutputClassifier(RandomForestClassifier())),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Test the pipeline on the test data\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: related\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.26      0.38      1247\n",
      "           1       0.80      0.97      0.88      3952\n",
      "           2       0.60      0.13      0.22        45\n",
      "\n",
      "    accuracy                           0.79      5244\n",
      "   macro avg       0.71      0.45      0.49      5244\n",
      "weighted avg       0.78      0.79      0.75      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: request\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      4325\n",
      "           1       0.89      0.42      0.57       919\n",
      "\n",
      "    accuracy                           0.89      5244\n",
      "   macro avg       0.89      0.70      0.75      5244\n",
      "weighted avg       0.89      0.89      0.87      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: offer\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5224\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: aid_related\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      3075\n",
      "           1       0.78      0.62      0.69      2169\n",
      "\n",
      "    accuracy                           0.77      5244\n",
      "   macro avg       0.77      0.75      0.75      5244\n",
      "weighted avg       0.77      0.77      0.77      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: medical_help\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4824\n",
      "           1       0.59      0.04      0.08       420\n",
      "\n",
      "    accuracy                           0.92      5244\n",
      "   macro avg       0.75      0.52      0.52      5244\n",
      "weighted avg       0.90      0.92      0.89      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: medical_products\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4979\n",
      "           1       0.63      0.05      0.08       265\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.79      0.52      0.53      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: search_and_rescue\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5098\n",
      "           1       0.50      0.01      0.03       146\n",
      "\n",
      "    accuracy                           0.97      5244\n",
      "   macro avg       0.74      0.51      0.51      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: security\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5160\n",
      "           1       0.50      0.01      0.02        84\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.74      0.51      0.51      5244\n",
      "weighted avg       0.98      0.98      0.98      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: military\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5077\n",
      "           1       0.88      0.04      0.08       167\n",
      "\n",
      "    accuracy                           0.97      5244\n",
      "   macro avg       0.92      0.52      0.53      5244\n",
      "weighted avg       0.97      0.97      0.96      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: child_alone\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5244\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       1.00      1.00      1.00      5244\n",
      "weighted avg       1.00      1.00      1.00      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: water\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4912\n",
      "           1       0.87      0.18      0.29       332\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.91      0.59      0.63      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: food\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      4666\n",
      "           1       0.86      0.43      0.57       578\n",
      "\n",
      "    accuracy                           0.93      5244\n",
      "   macro avg       0.89      0.71      0.77      5244\n",
      "weighted avg       0.92      0.93      0.92      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: shelter\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4821\n",
      "           1       0.86      0.22      0.35       423\n",
      "\n",
      "    accuracy                           0.93      5244\n",
      "   macro avg       0.90      0.61      0.66      5244\n",
      "weighted avg       0.93      0.93      0.92      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: clothing\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5153\n",
      "           1       0.67      0.04      0.08        91\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.83      0.52      0.54      5244\n",
      "weighted avg       0.98      0.98      0.98      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: money\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5121\n",
      "           1       0.71      0.04      0.08       123\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.85      0.52      0.53      5244\n",
      "weighted avg       0.97      0.98      0.97      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: missing_people\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5195\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.99      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: refugees\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5097\n",
      "           1       0.44      0.03      0.05       147\n",
      "\n",
      "    accuracy                           0.97      5244\n",
      "   macro avg       0.71      0.51      0.52      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: death\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4994\n",
      "           1       0.76      0.13      0.22       250\n",
      "\n",
      "    accuracy                           0.96      5244\n",
      "   macro avg       0.86      0.56      0.60      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: other_aid\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93      4521\n",
      "           1       0.80      0.02      0.04       723\n",
      "\n",
      "    accuracy                           0.86      5244\n",
      "   macro avg       0.83      0.51      0.49      5244\n",
      "weighted avg       0.86      0.86      0.81      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: infrastructure_related\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4927\n",
      "           1       0.00      0.00      0.00       317\n",
      "\n",
      "    accuracy                           0.94      5244\n",
      "   macro avg       0.47      0.50      0.48      5244\n",
      "weighted avg       0.88      0.94      0.91      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: transport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4986\n",
      "           1       0.77      0.07      0.12       258\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.86      0.53      0.55      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: buildings\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4972\n",
      "           1       0.64      0.03      0.05       272\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.79      0.51      0.51      5244\n",
      "weighted avg       0.93      0.95      0.93      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: electricity\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5137\n",
      "           1       1.00      0.03      0.05       107\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.99      0.51      0.52      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: tools\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5223\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: hospitals\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5191\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: shops\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5225\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: aid_centers\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5187\n",
      "           1       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: other_infrastructure\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5022\n",
      "           1       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.96      5244\n",
      "   macro avg       0.48      0.50      0.49      5244\n",
      "weighted avg       0.92      0.96      0.94      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: weather_related\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.91      3770\n",
      "           1       0.88      0.62      0.73      1474\n",
      "\n",
      "    accuracy                           0.87      5244\n",
      "   macro avg       0.87      0.79      0.82      5244\n",
      "weighted avg       0.87      0.87      0.86      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: floods\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4803\n",
      "           1       0.93      0.37      0.53       441\n",
      "\n",
      "    accuracy                           0.94      5244\n",
      "   macro avg       0.94      0.69      0.75      5244\n",
      "weighted avg       0.94      0.94      0.93      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: storm\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4779\n",
      "           1       0.84      0.44      0.58       465\n",
      "\n",
      "    accuracy                           0.94      5244\n",
      "   macro avg       0.89      0.72      0.77      5244\n",
      "weighted avg       0.94      0.94      0.93      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: fire\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5188\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: earthquake\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4710\n",
      "           1       0.91      0.73      0.81       534\n",
      "\n",
      "    accuracy                           0.97      5244\n",
      "   macro avg       0.94      0.86      0.90      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: cold\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5135\n",
      "           1       1.00      0.06      0.12       109\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.99      0.53      0.56      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: other_weather\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4971\n",
      "           1       0.40      0.01      0.03       273\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.67      0.51      0.50      5244\n",
      "weighted avg       0.92      0.95      0.92      5244\n",
      "\n",
      "------------------------------------------------------------\n",
      "Category: direct_report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      4253\n",
      "           1       0.84      0.37      0.52       991\n",
      "\n",
      "    accuracy                           0.87      5244\n",
      "   macro avg       0.86      0.68      0.72      5244\n",
      "weighted avg       0.87      0.87      0.85      5244\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert predictions and true values to DataFrame to match column names\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=Y.columns)\n",
    "y_test_df = pd.DataFrame(y_test, columns=Y.columns)\n",
    "\n",
    "# Iterate through each category and display classification metrics\n",
    "for column in Y.columns:\n",
    "    print(f'Category: {column}\\n')\n",
    "    print(classification_report(y_test_df[column], y_pred_df[column]))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for GridSearchCV\n",
    "parameters = {\n",
    "    #'vect__max_df': [0.75, 0.85, 1.0],  # Maximum document frequency for words\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # Unigrams or unigrams and bigrams\n",
    "    #'tfidf__use_idf': [True, False],  # Use IDF or not\n",
    "    #'tfidf__norm': ['l1', 'l2'],  # Normalization method\n",
    "    'clf__estimator__n_estimators': [50, 100, 200],  # Number of trees in RandomForest\n",
    "    #'clf__estimator__max_depth': [None, 10, 20],  # Maximum depth of trees\n",
    "    'clf__estimator__min_samples_split': [2, 3],  # Minimum samples required to split an internal node\n",
    "    #'clf__estimator__bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and parameter grid\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=3, n_jobs=-1)\n",
    "\n",
    "# Fit the model with GridSearchCV\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: related\n",
      "\n",
      "Accuracy: 0.80\n",
      "Precision: 0.61\n",
      "Recall: 0.54\n",
      "------------------------------\n",
      "Category: request\n",
      "\n",
      "Accuracy: 0.88\n",
      "Precision: 0.86\n",
      "Recall: 0.69\n",
      "------------------------------\n",
      "Category: offer\n",
      "\n",
      "Accuracy: 1.00\n",
      "Precision: 0.50\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: aid_related\n",
      "\n",
      "Accuracy: 0.74\n",
      "Precision: 0.74\n",
      "Recall: 0.73\n",
      "------------------------------\n",
      "Category: medical_help\n",
      "\n",
      "Accuracy: 0.92\n",
      "Precision: 0.80\n",
      "Recall: 0.51\n",
      "------------------------------\n",
      "Category: medical_products\n",
      "\n",
      "Accuracy: 0.95\n",
      "Precision: 0.47\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: search_and_rescue\n",
      "\n",
      "Accuracy: 0.98\n",
      "Precision: 0.49\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: security\n",
      "\n",
      "Accuracy: 0.98\n",
      "Precision: 0.49\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: military\n",
      "\n",
      "Accuracy: 0.97\n",
      "Precision: 0.48\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: child_alone\n",
      "\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "------------------------------\n",
      "Category: water\n",
      "\n",
      "Accuracy: 0.95\n",
      "Precision: 0.92\n",
      "Recall: 0.63\n",
      "------------------------------\n",
      "Category: food\n",
      "\n",
      "Accuracy: 0.93\n",
      "Precision: 0.89\n",
      "Recall: 0.67\n",
      "------------------------------\n",
      "Category: shelter\n",
      "\n",
      "Accuracy: 0.92\n",
      "Precision: 0.94\n",
      "Recall: 0.60\n",
      "------------------------------\n",
      "Category: clothing\n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 0.49\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: money\n",
      "\n",
      "Accuracy: 0.97\n",
      "Precision: 0.82\n",
      "Recall: 0.54\n",
      "------------------------------\n",
      "Category: missing_people\n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 0.49\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: refugees\n",
      "\n",
      "Accuracy: 0.96\n",
      "Precision: 0.48\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: death\n",
      "\n",
      "Accuracy: 0.95\n",
      "Precision: 0.88\n",
      "Recall: 0.54\n",
      "------------------------------\n",
      "Category: other_aid\n",
      "\n",
      "Accuracy: 0.89\n",
      "Precision: 0.94\n",
      "Recall: 0.52\n",
      "------------------------------\n",
      "Category: infrastructure_related\n",
      "\n",
      "Accuracy: 0.93\n",
      "Precision: 0.47\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: transport\n",
      "\n",
      "Accuracy: 0.96\n",
      "Precision: 0.48\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: buildings\n",
      "\n",
      "Accuracy: 0.94\n",
      "Precision: 0.97\n",
      "Recall: 0.52\n",
      "------------------------------\n",
      "Category: electricity\n",
      "\n",
      "Accuracy: 0.98\n",
      "Precision: 0.49\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: tools\n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 0.50\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: hospitals\n",
      "\n",
      "Accuracy: 0.98\n",
      "Precision: 0.49\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: shops\n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 0.50\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: aid_centers\n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 0.49\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: other_infrastructure\n",
      "\n",
      "Accuracy: 0.96\n",
      "Precision: 0.48\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: weather_related\n",
      "\n",
      "Accuracy: 0.87\n",
      "Precision: 0.87\n",
      "Recall: 0.80\n",
      "------------------------------\n",
      "Category: floods\n",
      "\n",
      "Accuracy: 0.94\n",
      "Precision: 0.93\n",
      "Recall: 0.65\n",
      "------------------------------\n",
      "Category: storm\n",
      "\n",
      "Accuracy: 0.91\n",
      "Precision: 0.87\n",
      "Recall: 0.57\n",
      "------------------------------\n",
      "Category: fire\n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 0.50\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: earthquake\n",
      "\n",
      "Accuracy: 0.95\n",
      "Precision: 0.91\n",
      "Recall: 0.77\n",
      "------------------------------\n",
      "Category: cold\n",
      "\n",
      "Accuracy: 0.98\n",
      "Precision: 0.49\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: other_weather\n",
      "\n",
      "Accuracy: 0.95\n",
      "Precision: 0.47\n",
      "Recall: 0.50\n",
      "------------------------------\n",
      "Category: direct_report\n",
      "\n",
      "Accuracy: 0.85\n",
      "Precision: 0.81\n",
      "Recall: 0.64\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Predict using the tuned model\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "# Convert predictions and true values to DataFrame to match column names\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=Y.columns)\n",
    "y_test_df = pd.DataFrame(y_test, columns=Y.columns)\n",
    "\n",
    "\n",
    "# Iterate through each category and display classification metrics\n",
    "for column in Y.columns:\n",
    "    print(f'Category: {column}\\n')\n",
    "    \n",
    "    # Get the true and predicted values for the current column\n",
    "    y_true = y_test_df[column]\n",
    "    y_pred = y_pred_df[column]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)  # Use 'binary' for binary targets\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    #conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    #print(classification_report(y_test_df[column], y_pred_df[column]))\n",
    "    #print(f'Confusion Matrix:\\n{conf_matrix}\\n')\n",
    "    print('-' * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our accuracy is pretty high but the Recall is in some cases low. lets try to get an overall high recall score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 4860 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4860 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1618, in fit_transform\n    results = self._parallel_func(X, y, fit_params, _fit_transform_one)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1642, in _parallel_func\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n    return super().__call__(iterable_with_config)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12428\\776172440.py\", line 19, in transform\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py\", line 4924, in apply\n    ).apply()\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\", line 1427, in apply\n    return self.apply_standard()\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\", line 1507, in apply_standard\n    mapped = obj._map_values(\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py\", line 921, in _map_values\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py\", line 1743, in map_array\n    return lib.map_infer(values, mapper, convert=convert)\n  File \"lib.pyx\", line 2972, in pandas._libs.lib.map_infer\n  File \"C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12428\\776172440.py\", line 10, in starting_verb\nIndexError: list index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 93\u001b[0m\n\u001b[0;32m     90\u001b[0m cv2 \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline2, param_grid\u001b[38;5;241m=\u001b[39mparameters, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Fit the model with GridSearchCV\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Predict using the tuned model\u001b[39;00m\n\u001b[0;32m     96\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 947\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 4860 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4860 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1618, in fit_transform\n    results = self._parallel_func(X, y, fit_params, _fit_transform_one)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1642, in _parallel_func\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n    return super().__call__(iterable_with_config)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12428\\776172440.py\", line 19, in transform\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py\", line 4924, in apply\n    ).apply()\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\", line 1427, in apply\n    return self.apply_standard()\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\", line 1507, in apply_standard\n    mapped = obj._map_values(\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py\", line 921, in _map_values\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n  File \"c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py\", line 1743, in map_array\n    return lib.map_infer(values, mapper, convert=convert)\n  File \"lib.pyx\", line 2972, in pandas._libs.lib.map_infer\n  File \"C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12428\\776172440.py\", line 10, in starting_verb\nIndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "# lets add a Starting verb Extractor for a better classification of sentences:\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in [\"VB\", \"VBP\"] or first_word == \"RT\":\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)\n",
    "\n",
    "\n",
    "# pipeline with featureUnion\n",
    "\n",
    "pipeline2 = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"features\",\n",
    "            FeatureUnion(\n",
    "                [\n",
    "                    (\n",
    "                        \"text_pipeline\",\n",
    "                        Pipeline(\n",
    "                            [\n",
    "                                ((\"vect\", CountVectorizer(tokenizer=tokenize))),\n",
    "                                ((\"tfidf\", TfidfTransformer())),\n",
    "                            ]\n",
    "                        ),\n",
    "                    ),\n",
    "                    (\"starting_verb\", StartingVerbExtractor()),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\"multi_rf\", MultiOutputClassifier(RandomForestClassifier())),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "parameters = {\n",
    "    \"features__text_pipeline__vect__ngram_range\": (\n",
    "        (1, 1),\n",
    "        (1, 2),\n",
    "    ),  # Unigrams or unigrams and bigrams\n",
    "    \"features__text_pipeline__vect__max_df\": [\n",
    "        0.5,\n",
    "        0.75,\n",
    "        1.0,\n",
    "    ],  # Maximum document frequency for words\n",
    "    \"features__text_pipeline__vect__max_features\": (\n",
    "        None,\n",
    "        5000,\n",
    "        10000,\n",
    "    ),  # Maximum document frequency for words\n",
    "    \"features__text_pipeline__tfidf__use_idf\": [\n",
    "        True,\n",
    "        False,\n",
    "    ],  # Whether to use idf in TfidfTransformer\n",
    "    # \"features__text_pipeline__tfidf__norm\": [\"l1\", \"l2\"],  # Normalization method\n",
    "    \"multi_rf__estimator__n_estimators\": [\n",
    "        50,\n",
    "        100,\n",
    "        200,\n",
    "    ],  # Number of trees in RandomForest\n",
    "    # \"multi_rf__estimator__max_depth\": [None, 10, 20],  # Maximum depth of trees\n",
    "    \"multi_rf__estimator__min_samples_split\": [\n",
    "        2,\n",
    "        3,\n",
    "    ],  # Minimum samples required to split an internal node\n",
    "    #'multi_rf__estimator__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    \"features__transformer_weights\": (\n",
    "        {\"text_pipeline\": 1, \"starting_verb\": 0.5},\n",
    "        {\"text_pipeline\": 0.5, \"starting_verb\": 1},\n",
    "        {\"text_pipeline\": 0.8, \"starting_verb\": 1},\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and parameter grid\n",
    "cv2 = GridSearchCV(pipeline2, param_grid=parameters, verbose=3, n_jobs=-1)\n",
    "\n",
    "# Fit the model with GridSearchCV\n",
    "cv2.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the tuned model\n",
    "y_pred = cv2.predict(X_test)\n",
    "\n",
    "# Convert predictions and true values to DataFrame to match column names\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=Y.columns)\n",
    "y_test_df = pd.DataFrame(y_test, columns=Y.columns)\n",
    "\n",
    "# Iterate through each category and display classification metrics\n",
    "for column in Y.columns:\n",
    "    print(f\"Category: {column}\\n\")\n",
    "\n",
    "    # Get the true and predicted values for the current column\n",
    "    y_true = y_test_df[column]\n",
    "    y_pred = y_pred_df[column]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(\n",
    "        y_true, y_pred, average=\"macro\", zero_division=0\n",
    "    )  # Use 'binary' for binary targets\n",
    "    recall = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    # conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    # print(f'Confusion Matrix:\\n{conf_matrix}\\n')\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train_classifier.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
